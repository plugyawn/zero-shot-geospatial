{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, clip, csv, json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rasterio.enums import Resampling\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"geolibs/data/BigEarthNet-S2\"\n",
    "bsize, psize = 512, 336\n",
    "num_workers = 8\n",
    "\n",
    "model_name = \"ViT-L/14@336px\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image-id</th>\n",
       "      <th>image:01</th>\n",
       "      <th>date:01</th>\n",
       "      <th>type</th>\n",
       "      <th>geometry</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63a44d38d053bf87a930ddb4</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_0_49.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63a44d38d053bf87a930ddc1</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_0_62.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63a44d38d053bf87a930de15</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_11_41.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63a44d38d053bf87a930de5c</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_12_59.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>63a44d38d053bf87a930de74</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_12_83.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  image-id  \\\n",
       "0           0  63a44d38d053bf87a930ddb4   \n",
       "1           1  63a44d38d053bf87a930ddc1   \n",
       "2           2  63a44d38d053bf87a930de15   \n",
       "3           3  63a44d38d053bf87a930de5c   \n",
       "4           4  63a44d38d053bf87a930de74   \n",
       "\n",
       "                                           image:01  \\\n",
       "0   rasters/raw/S2A_MSIL2A_20170613T101031_0_49.tar   \n",
       "1   rasters/raw/S2A_MSIL2A_20170613T101031_0_62.tar   \n",
       "2  rasters/raw/S2A_MSIL2A_20170613T101031_11_41.tar   \n",
       "3  rasters/raw/S2A_MSIL2A_20170613T101031_12_59.tar   \n",
       "4  rasters/raw/S2A_MSIL2A_20170613T101031_12_83.tar   \n",
       "\n",
       "                     date:01  type  geometry         labels  \n",
       "0  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "1  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "2  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "3  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "4  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV/val.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    means = [0.48145, 0.45782, 0.40821]\n",
    "    stds = [0.26863, 0.26130, 0.27578]\n",
    "\n",
    "    image = image / 255\n",
    "    for idx in range(3):\n",
    "        image[idx,:,:] = (image[idx,:,:]-means[idx])/stds[idx]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BigEarthNetS2InferenceDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        root_vec_dir = \"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV\"\n",
    "        meta_file = \"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV/metadata.json\"\n",
    "        rasters_root_dir = \"/home/progyan/data/cogs/\"\n",
    "        with open(meta_file) as out:\n",
    "            task_meta = json.load(out)\n",
    "\n",
    "        classes = [lbl_meta[\"options\"] for lbl_meta in task_meta[\"label:metadata\"]][0]\n",
    "        cls_idx_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        \n",
    "        vec_df = pd.read_csv(f\"{root_vec_dir}/test.csv\")\n",
    "        vec_df[\"image\"] = vec_df[\"image:01\"].apply(lambda x: f'{rasters_root_dir}{x.split(\"/\")[-1]}')\n",
    "        vec_df[\"image\"] = vec_df[\"image\"].apply(lambda x: f'{x.split(\".\")[0]}.tif')\n",
    "        vec_df[\"label\"] = vec_df[\"labels\"].apply(lambda x: [cls_idx_map[l] for l in x.split(\"\\t\")])\n",
    "        vec_df[\"label\"] = vec_df[\"label\"].apply(lambda x: [1 if i in x else 0 for i in range(len(classes))])\n",
    "        vec_df.drop(['image-id','image:01','date:01','type','geometry','labels'],axis=1,inplace=True)\n",
    "\n",
    "        self.vec_df = vec_df\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vec_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df_entry = self.vec_df.loc[idx]\n",
    "        image = rio.open(df_entry[\"image\"]).read(out_shape=[3,psize,psize], resampling=Resampling.bilinear)    \n",
    "        smpl_map = {\n",
    "            \"image\": normalize(image),\n",
    "            \"label\": np.array(df_entry[\"label\"], dtype=np.int16)\n",
    "        }\n",
    "\n",
    "        return smpl_map\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of many {}.',\n",
    "    'a sculpture of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a tattoo of a {}.',\n",
    "    'the embroidered {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'the plastic {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a plastic {}.',\n",
    "    'a photo of the dirty {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a {} in a video game.',\n",
    "    'a photo of one {}.',\n",
    "    'a doodle of a {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'the origami {}.',\n",
    "    'the {} in a video game.',\n",
    "    'a sketch of a {}.',\n",
    "    'a doodle of the {}.',\n",
    "    'a origami {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'the toy {}.',\n",
    "    'a rendition of the {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a rendition of a {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a photo of a weird {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a sketch of the {}.',\n",
    "    'a embroidered {}.',\n",
    "    'a pixelated photo of a {}.',\n",
    "    'itap of the {}.',\n",
    "    'a jpeg corrupted photo of the {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a plushie {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'the cartoon {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a black and white photo of a {}.',\n",
    "    'the plushie {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'itap of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "    'a toy {}.',\n",
    "    'itap of my {}.',\n",
    "    'a photo of a cool {}.',\n",
    "    'a photo of a small {}.',\n",
    "    'a tattoo of the {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_templates = [\n",
    "    \"an overhead view of a {}\",\n",
    "    \"a satellite view of a {}\",\n",
    "    \"an aerial view of a {}\",\n",
    "    \"a clear overhead view of a {}\",\n",
    "    \"a blurry overhead view of a {}\",\n",
    "    \"a low resolution overhead view of a {}\",\n",
    "    \"a high resolution overhead view of a {}\",\n",
    "    \"a clear satellite view of a {}\",\n",
    "    \"a blurry satellite view of a {}\",\n",
    "    \"a low resolution satellite view of a {}\",\n",
    "    \"a high resolution satellite view of a {}\",\n",
    "    \"a clear satellite view of a {}\",\n",
    "    \"a blurry satellite view of a {}\",\n",
    "    \"a low resolution satellite view of a {}\",\n",
    "    \"a high resolution satellite view of a {}\",\n",
    "    \"an overhead image of a {}\",\n",
    "    \"a satellite image of a {}\",\n",
    "    \"an aerial image of a {}\",\n",
    "    \"a clear overhead image of a {}\",\n",
    "    \"a blurry overhead image of a {}\",\n",
    "    \"a low resolution overhead image of a {}\",\n",
    "    \"a high resolution overhead image of a {}\",\n",
    "    \"a clear satellite image of a {}\",\n",
    "    \"a blurry satellite image of a {}\",\n",
    "    \"a low resolution satellite image of a {}\",\n",
    "    \"a high resolution satellite image of a {}\",\n",
    "    \"a clear satellite image of a {}\",\n",
    "    \"a blurry satellite image of a {}\",\n",
    "    \"a low resolution satellite image of a {}\",\n",
    "    \"a high resolution satellite image of a {}\",  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zeroshot_classifier(classnames, templates):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            texts = [template.format(classname) for template in templates] #format with class\n",
    "            texts = clip.tokenize(texts).cuda() #tokenize\n",
    "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geolibs/data/BigEarthNet-S2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bens2_ds = BigEarthNetS2InferenceDataset(root_dir=root_dir)\n",
    "\n",
    "classes = bens2_ds.classes\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"an image of {cls}\" for cls in bens2_ds.classes]\n",
    "texts = clip.tokenize(texts).to(device)\n",
    "\n",
    "text_features = model.encode_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/246 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 23.70 GiB total capacity; 16.84 GiB already allocated; 962.50 MiB free; 20.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m images \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m target \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 25\u001b[0m im_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m model(images, texts)\n\u001b[1;32m     29\u001b[0m preds_01 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(logits_per_image,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:341\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:232\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(x)\n\u001b[1;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NLD -> LND\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# LND -> NLD\u001b[39;00m\n\u001b[1;32m    235\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x[:, \u001b[38;5;241m0\u001b[39m, :])\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:191\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    190\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m--> 191\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:168\u001b[0m, in \u001b[0;36mQuickGELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.702\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 23.70 GiB total capacity; 16.84 GiB already allocated; 962.50 MiB free; 20.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import HammingDistance, Accuracy\n",
    "\n",
    "acc_inst_01 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_02 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_03 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_04 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_05 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_06 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_07 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "\n",
    "bens2_dl = DataLoader(bens2_ds, batch_size=bsize, shuffle=False, num_workers=num_workers)\n",
    "# acc_inst = MultilabelAccuracy(num_labels=num_classes).to(device)\n",
    "\n",
    "# ham_dist_03 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_04 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_05 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_06 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_07 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(bens2_dl):\n",
    "        images = sample[\"image\"].to(device)\n",
    "        target = sample[\"label\"].to(device)\n",
    "        \n",
    "        im_features = model.encode_image(images)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        \n",
    "        preds_01 = torch.topk(logits_per_image,1).indices\n",
    "        preds_02 = torch.topk(logits_per_image,2).indices\n",
    "        preds_03 = torch.topk(logits_per_image,3).indices\n",
    "        preds_04 = torch.topk(logits_per_image,4).indices\n",
    "        preds_05 = torch.topk(logits_per_image,5).indices\n",
    "        preds_06 = torch.topk(logits_per_image,6).indices\n",
    "        preds_07 = torch.topk(logits_per_image,7).indices\n",
    "\n",
    "        oh_preds_01 = F.one_hot(preds_01, num_classes).squeeze(1)\n",
    "        oh_preds_02 = torch.sum(F.one_hot(preds_02, num_classes),1)\n",
    "        oh_preds_03 = torch.sum(F.one_hot(preds_03, num_classes),1)\n",
    "        oh_preds_04 = torch.sum(F.one_hot(preds_04, num_classes),1)\n",
    "        oh_preds_05 = torch.sum(F.one_hot(preds_05, num_classes),1)\n",
    "        oh_preds_06 = torch.sum(F.one_hot(preds_06, num_classes),1)\n",
    "        oh_preds_07 = torch.sum(F.one_hot(preds_07, num_classes),1)\n",
    "\n",
    "        acc_inf_01 = acc_inst_01(oh_preds_01, target)\n",
    "        acc_inf_02 = acc_inst_02(oh_preds_02, target)\n",
    "        acc_inf_03 = acc_inst_03(oh_preds_03, target)\n",
    "        acc_inf_04 = acc_inst_04(oh_preds_04, target)\n",
    "        acc_inf_05 = acc_inst_05(oh_preds_05, target)\n",
    "        acc_inf_06 = acc_inst_06(oh_preds_06, target)\n",
    "        acc_inf_07 = acc_inst_07(oh_preds_07, target)\n",
    "\n",
    "        # ham_dist_inf_03 = ham_dist_03(oh_preds_03, target)\n",
    "        # ham_dist_inf_04 = ham_dist_04(oh_preds_04, target)\n",
    "        # ham_dist_inf_05 = ham_dist_05(oh_preds_05, target)\n",
    "        # ham_dist_inf_06 = ham_dist_06(oh_preds_06, target)\n",
    "        # ham_dist_inf_07 = ham_dist_07(oh_preds_07, target)\n",
    "        #acc_inf= acc_inst(oh_preds, target)\n",
    "\n",
    "    avg_acc_inst_01 = acc_inst_01.compute()\n",
    "    avg_acc_inst_02 = acc_inst_02.compute()\n",
    "    avg_acc_inst_03 = acc_inst_03.compute()\n",
    "    avg_acc_inst_04 = acc_inst_04.compute()\n",
    "    avg_acc_inst_05 = acc_inst_05.compute()\n",
    "    avg_acc_inst_06 = acc_inst_06.compute()\n",
    "    avg_acc_inst_07 = acc_inst_07.compute()\n",
    "\n",
    "    # avg_ham_dist_03 = ham_dist_03.compute()\n",
    "    # avg_ham_dist_04 = ham_dist_04.compute()\n",
    "    # avg_ham_dist_05 = ham_dist_05.compute()\n",
    "    # avg_ham_dist_06 = ham_dist_06.compute()\n",
    "    # avg_ham_dist_07 = ham_dist_07.compute()\n",
    "    print(f\"top 1: {avg_acc_inst_01}\")\n",
    "    print(f\"top 2: {avg_acc_inst_02}\")   \n",
    "    print(f\"top 3: {avg_acc_inst_03}\")\n",
    "    print(f\"top 4: {avg_acc_inst_04}\")\n",
    "    print(f\"top 5: {avg_acc_inst_05}\")\n",
    "    print(f\"top 6: {avg_acc_inst_06}\")\n",
    "    print(f\"top 7: {avg_acc_inst_07}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "oh_preds_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vec_df = pd.read_csv(f\"/mnt/NVME2/{root_dir}/vectors/random-split-6_2022_12_30-01_32_22/CSV/test.csv\")\n",
    "vec_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/progyan/miniconda/envs/mamba-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - transformers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    abseil-cpp-20211102.0      |       h27087fc_1         1.1 MB  conda-forge\n",
      "    aiohttp-3.8.4              |  py311h459d7ec_1         538 KB  conda-forge\n",
      "    aiosignal-1.3.1            |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    async-timeout-4.0.2        |     pyhd8ed1ab_0           9 KB  conda-forge\n",
      "    datasets-2.13.0            |     pyhd8ed1ab_0         333 KB  conda-forge\n",
      "    dill-0.3.6                 |     pyhd8ed1ab_1          81 KB  conda-forge\n",
      "    frozenlist-1.3.3           |  py311hd4cff14_0          45 KB  conda-forge\n",
      "    fsspec-2023.6.0            |     pyh1a96a4e_0         116 KB  conda-forge\n",
      "    gflags-2.2.2               |    he1b5a44_1004         114 KB  conda-forge\n",
      "    glog-0.5.0                 |       h48cff8f_0         104 KB  conda-forge\n",
      "    huggingface_hub-0.15.1     |     pyhd8ed1ab_0         165 KB  conda-forge\n",
      "    joblib-1.2.0               |     pyhd8ed1ab_0         205 KB  conda-forge\n",
      "    libevent-2.1.10            |       h28343ad_4         1.1 MB  conda-forge\n",
      "    libprotobuf-3.20.3         |       h3eb15da_0         2.2 MB  conda-forge\n",
      "    libthrift-0.15.0           |       h362ad58_1         4.5 MB  conda-forge\n",
      "    multidict-6.0.4            |  py311h2582759_0          56 KB  conda-forge\n",
      "    multiprocess-0.70.14       |  py311hd4cff14_3         315 KB  conda-forge\n",
      "    python-xxhash-3.2.0        |  py311h2582759_0          22 KB  conda-forge\n",
      "    re2-2022.04.01             |       h27087fc_0         212 KB  conda-forge\n",
      "    regex-2023.6.3             |  py311h459d7ec_0         395 KB  conda-forge\n",
      "    responses-0.18.0           |     pyhd8ed1ab_0          35 KB  conda-forge\n",
      "    sacremoses-0.0.53          |     pyhd8ed1ab_0         427 KB  conda-forge\n",
      "    safetensors-0.3.1          |  py311h46250e7_0         973 KB  conda-forge\n",
      "    tokenizers-0.13.3          |  py311h1b04a43_0         3.9 MB  conda-forge\n",
      "    transformers-4.30.2        |     pyhd8ed1ab_1         2.4 MB  conda-forge\n",
      "    xxhash-0.8.1               |       h0b41bf4_0          87 KB  conda-forge\n",
      "    yarl-1.9.2                 |  py311h459d7ec_0         103 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        19.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  abseil-cpp         conda-forge/linux-64::abseil-cpp-20211102.0-h27087fc_1 \n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.8.4-py311h459d7ec_1 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  arrow-cpp          pkgs/main/linux-64::arrow-cpp-11.0.0-h374c478_1 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0 \n",
      "  aws-c-common       pkgs/main/linux-64::aws-c-common-0.6.8-h5eee18b_1 \n",
      "  aws-c-event-stream pkgs/main/linux-64::aws-c-event-stream-0.1.6-h6a678d5_6 \n",
      "  aws-checksums      pkgs/main/linux-64::aws-checksums-0.1.11-h5eee18b_2 \n",
      "  aws-sdk-cpp        pkgs/main/linux-64::aws-sdk-cpp-1.8.185-h721c034_1 \n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3 \n",
      "  datasets           conda-forge/noarch::datasets-2.13.0-pyhd8ed1ab_0 \n",
      "  dill               conda-forge/noarch::dill-0.3.6-pyhd8ed1ab_1 \n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.3.3-py311hd4cff14_0 \n",
      "  fsspec             conda-forge/noarch::fsspec-2023.6.0-pyh1a96a4e_0 \n",
      "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004 \n",
      "  glog               conda-forge/linux-64::glog-0.5.0-h48cff8f_0 \n",
      "  grpc-cpp           pkgs/main/linux-64::grpc-cpp-1.48.2-he1ff14a_1 \n",
      "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.15.1-pyhd8ed1ab_0 \n",
      "  joblib             conda-forge/noarch::joblib-1.2.0-pyhd8ed1ab_0 \n",
      "  libevent           conda-forge/linux-64::libevent-2.1.10-h28343ad_4 \n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.20.3-h3eb15da_0 \n",
      "  libthrift          conda-forge/linux-64::libthrift-0.15.0-h362ad58_1 \n",
      "  multidict          conda-forge/linux-64::multidict-6.0.4-py311h2582759_0 \n",
      "  multiprocess       conda-forge/linux-64::multiprocess-0.70.14-py311hd4cff14_3 \n",
      "  orc                pkgs/main/linux-64::orc-1.7.4-hb3bc3d3_1 \n",
      "  pyarrow            pkgs/main/linux-64::pyarrow-11.0.0-py311hd8e8d9b_0 \n",
      "  python-xxhash      conda-forge/linux-64::python-xxhash-3.2.0-py311h2582759_0 \n",
      "  re2                conda-forge/linux-64::re2-2022.04.01-h27087fc_0 \n",
      "  regex              conda-forge/linux-64::regex-2023.6.3-py311h459d7ec_0 \n",
      "  responses          conda-forge/noarch::responses-0.18.0-pyhd8ed1ab_0 \n",
      "  sacremoses         conda-forge/noarch::sacremoses-0.0.53-pyhd8ed1ab_0 \n",
      "  safetensors        conda-forge/linux-64::safetensors-0.3.1-py311h46250e7_0 \n",
      "  tokenizers         conda-forge/linux-64::tokenizers-0.13.3-py311h1b04a43_0 \n",
      "  transformers       conda-forge/noarch::transformers-4.30.2-pyhd8ed1ab_1 \n",
      "  utf8proc           pkgs/main/linux-64::utf8proc-2.6.1-h27cfd23_0 \n",
      "  xxhash             conda-forge/linux-64::xxhash-0.8.1-h0b41bf4_0 \n",
      "  yarl               conda-forge/linux-64::yarl-1.9.2-py311h459d7ec_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.05.30~ --> conda-forge::ca-certificates-2023.5.7-hbcca054_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "gflags-2.2.2         | 114 KB    |                                       |   0% \n",
      "responses-0.18.0     | 35 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "gflags-2.2.2         | 114 KB    | #####2                                |  14% \u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     | ######7                               |  18% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | 2                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ####################3                 |  55% \u001b[A\u001b[A\n",
      "responses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\n",
      "responses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gflags-2.2.2         | 114 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | #######5                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ###############3                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | #######################7              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ###############################1      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ################################7     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | #######3                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##########5                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | ###################################7  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##########################7           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge transformers -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth : ['Coniferous forest', 'Mixed forest', 'Transitional woodland/shrub']\n",
      "\n",
      "Top 5: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric']\n",
      "\n",
      "Top 10: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Mixed forest', 'Continuous urban fabric', 'Sparsely vegetated areas', 'Inland marshes']\n",
      "\n",
      "Top 15: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Continuous urban fabric', 'Mixed forest', 'Sparsely vegetated areas', 'Inland marshes', 'Burnt areas', 'Transitional woodland/shrub', 'Non-irrigated arable land', 'Rice fields', 'Mineral extraction sites']\n",
      "\n",
      "Top 20: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Mixed forest', 'Continuous urban fabric', 'Sparsely vegetated areas', 'Inland marshes', 'Burnt areas', 'Transitional woodland/shrub', 'Rice fields', 'Non-irrigated arable land', 'Mineral extraction sites', 'Complex cultivation patterns', 'Salt marshes', 'Bare rock', 'Estuaries', 'Sea and ocean']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = preprocess(Image.open(bens2_ds.vec_df.loc[0][\"image\"])).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(bens2_ds.classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "\n",
    "    idx_tp05 = torch.topk(logits_per_image, 5).indices.cpu().tolist()[0]\n",
    "    idx_tp10 = torch.topk(logits_per_image, 10).indices.cpu().tolist()[0]\n",
    "    idx_tp15 = torch.topk(logits_per_image, 15).indices.cpu().tolist()[0]\n",
    "    idx_tp20 = torch.topk(logits_per_image, 20).indices.cpu().tolist()[0]\n",
    "\n",
    "    cls_tp05 = [bens2_ds.classes[idx] for idx in idx_tp05]\n",
    "    cls_tp10 = [bens2_ds.classes[idx] for idx in idx_tp10]\n",
    "    cls_tp15 = [bens2_ds.classes[idx] for idx in idx_tp15]\n",
    "    cls_tp20 = [bens2_ds.classes[idx] for idx in idx_tp20]\n",
    "\n",
    "    gr_truth = vec_df.loc[8]['labels'].split('\\t')\n",
    "    \n",
    "    print(f\"Ground truth : {gr_truth}\")\n",
    "    print(f\"\\nTop 5: {cls_tp05}\")\n",
    "    print(f\"\\nTop 10: {cls_tp10}\")\n",
    "    print(f\"\\nTop 15: {cls_tp15}\")\n",
    "    print(f\"\\nTop 20: {cls_tp20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/progyan/.local/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/progyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/progyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (1.4.2) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['sentencepiece']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch     \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/linux-64      \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/main/noarch     \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/r/linux-64      \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64                                               No change\n",
      "pkgs/r/noarch                                                 No change\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m 338.3kB /  ??.?MB @   1.3MB/s  0.3s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\n",
      "pkgs/main/linux-64   \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\n",
      "pkgs/main/noarch     \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m 405.5kB /  ??.?MB @   1.6MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch                                   850.6kB @   2.4MB/s  0.4s\n",
      "[+] 0.4s\n",
      "conda-forge/linux-64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   1.1MB /  ??.?MB @   2.7MB/s  0.4s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\n",
      "pkgs/main/linux-64   \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   1.6MB /  ??.?MB @   3.2MB/s  0.5s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.5s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   2.2MB /  ??.?MB @   3.6MB/s  0.6s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.6s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   2.6MB /  ??.?MB @   3.7MB/s  0.7s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.7s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m   3.0MB /  ??.?MB @   3.8MB/s  0.8s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.8s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   3.3MB /  ??.?MB @   3.9MB/s  0.9s\n",
      "conda-forge/noarch   \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.9s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   3.9MB /  ??.?MB @   4.1MB/s  1.0s\n",
      "conda-forge/noarch   \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.0s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m   4.4MB /  ??.?MB @   4.2MB/s  1.1s\n",
      "conda-forge/noarch   \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.1s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   5.0MB /  ??.?MB @   4.3MB/s  1.2s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m 429.9kB /  ??.?MB @ 366.2kB/s  1.2s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 442.4kB /  ??.?MB @ 374.7kB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "conda-forge/linux-64 \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   5.5MB /  ??.?MB @   4.4MB/s  1.3s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m 966.2kB /  ??.?MB @ 757.2kB/s  1.3s\n",
      "pkgs/main/linux-64   \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 962.6kB /  ??.?MB @ 751.2kB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "conda-forge/linux-64 \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   6.1MB /  ??.?MB @   4.5MB/s  1.4s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   1.6MB /  ??.?MB @   1.1MB/s  1.4s\n",
      "pkgs/main/linux-64   \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   1.5MB /  ??.?MB @   1.1MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   6.7MB /  ??.?MB @   4.5MB/s  1.5s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   2.2MB /  ??.?MB @   1.5MB/s  1.5s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   2.0MB /  ??.?MB @   1.4MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   7.2MB /  ??.?MB @   4.6MB/s  1.6s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   2.6MB /  ??.?MB @   1.7MB/s  1.6s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   2.6MB /  ??.?MB @   1.6MB/s  1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   7.8MB /  ??.?MB @   4.6MB/s  1.7s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m   3.2MB /  ??.?MB @   1.9MB/s  1.7s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   3.1MB /  ??.?MB @   1.8MB/s  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   8.4MB /  ??.?MB @   4.7MB/s  1.8s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   3.7MB /  ??.?MB @   2.1MB/s  1.8s\n",
      "pkgs/main/linux-64   \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   3.6MB /  ??.?MB @   2.0MB/s  1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   9.0MB /  ??.?MB @   4.8MB/s  1.9s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   4.0MB /  ??.?MB @   2.2MB/s  1.9s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   4.1MB /  ??.?MB @   2.2MB/s  1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   9.5MB /  ??.?MB @   4.8MB/s  2.0s\n",
      "conda-forge/noarch   \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   4.5MB /  ??.?MB @   2.3MB/s  2.0s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   4.7MB /  ??.?MB @   2.3MB/s  2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  10.1MB /  ??.?MB @   4.8MB/s  2.1s\n",
      "conda-forge/noarch   \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   5.1MB /  ??.?MB @   2.5MB/s  2.1s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   5.2MB /  ??.?MB @   2.5MB/s  2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  10.7MB /  ??.?MB @   4.9MB/s  2.2s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   5.6MB /  ??.?MB @   2.6MB/s  2.2s\n",
      "pkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   5.5MB /  ??.?MB @   2.6MB/s  2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m  10.7MB @   4.9MB/s             2.3s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   5.9MB @   2.7MB/s             2.3s\n",
      "pkgs/main/linux-64   ━━━━━━━━━━━━━━━━━━━━━━   5.9MB @   2.6MB/s Finalizing  2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                 @   2.6MB/s  2.3s\n",
      "[+] 2.4s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m  11.2MB /  ??.?MB @   4.8MB/s  2.4s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   6.4MB /  ??.?MB @   2.7MB/s  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "conda-forge/linux-64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m  12.1MB /  ??.?MB @   4.9MB/s  2.5s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   7.3MB /  ??.?MB @   2.9MB/s  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "conda-forge/linux-64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  12.6MB /  ??.?MB @   4.9MB/s  2.6s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   7.8MB /  ??.?MB @   3.0MB/s  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m  13.2MB /  ??.?MB @   5.0MB/s  2.7s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   8.4MB /  ??.?MB @   3.1MB/s  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m  13.8MB /  ??.?MB @   5.0MB/s  2.8s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   8.9MB /  ??.?MB @   3.2MB/s  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m  14.3MB /  ??.?MB @   5.0MB/s  2.9s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   9.5MB /  ??.?MB @   3.3MB/s  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m  14.9MB /  ??.?MB @   5.0MB/s  3.0s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m  10.0MB /  ??.?MB @   3.4MB/s  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m  15.4MB /  ??.?MB @   5.0MB/s  3.1s\n",
      "conda-forge/noarch   \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m  10.5MB /  ??.?MB @   3.4MB/s  3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  16.0MB /  ??.?MB @   5.1MB/s  3.2s\n",
      "conda-forge/noarch   \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  10.9MB /  ??.?MB @   3.4MB/s  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m  16.5MB /  ??.?MB @   5.1MB/s  3.3s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m  11.5MB /  ??.?MB @   3.5MB/s  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m  17.1MB /  ??.?MB @   5.1MB/s  3.4s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m  11.9MB /  ??.?MB @   3.5MB/s  3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "conda-forge/linux-64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m  17.7MB /  ??.?MB @   5.1MB/s  3.5s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m  12.3MB /  ??.?MB @   3.5MB/s  3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "conda-forge/linux-64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  18.2MB /  ??.?MB @   5.1MB/s  3.6s\n",
      "conda-forge/noarch   \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m  12.7MB /  ??.?MB @   3.5MB/s  3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  18.4MB /  ??.?MB @   5.1MB/s  3.7s\n",
      "conda-forge/noarch   \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m  12.9MB /  ??.?MB @   3.6MB/s  3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "conda-forge/linux-64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  18.4MB @   5.1MB/s             3.8s\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━━━  13.1MB @   3.6MB/s Finalizing  3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                 @   3.6MB/s  3.9s\n",
      "[+] 3.9s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m  19.1MB /  ??.?MB @   4.9MB/s  3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m  20.4MB /  ??.?MB @   5.1MB/s  4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m  20.7MB /  ??.?MB @   5.1MB/s  4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m  21.2MB /  ??.?MB @   5.1MB/s  4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m  21.7MB /  ??.?MB @   5.1MB/s  4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  22.2MB /  ??.?MB @   5.1MB/s  4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  22.7MB /  ??.?MB @   5.1MB/s  4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  23.2MB /  ??.?MB @   5.1MB/s  4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "conda-forge/linux-64 \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  23.7MB /  ??.?MB @   5.1MB/s  4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "conda-forge/linux-64 \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  24.2MB /  ??.?MB @   5.1MB/s  4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  24.7MB /  ??.?MB @   5.1MB/s  4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m  25.3MB /  ??.?MB @   5.1MB/s  5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m  25.9MB /  ??.?MB @   5.1MB/s  5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m  26.4MB /  ??.?MB @   5.1MB/s  5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m  26.9MB /  ??.?MB @   5.1MB/s  5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  27.4MB /  ??.?MB @   5.1MB/s  5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  27.9MB /  ??.?MB @   5.1MB/s  5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  27.9MB /  ??.?MB @   5.1MB/s  5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  28.9MB /  ??.?MB @   5.1MB/s  5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "conda-forge/linux-64 \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  29.4MB /  ??.?MB @   5.1MB/s  5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
      "conda-forge/linux-64 \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  29.8MB /  ??.?MB @   5.1MB/s  5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  30.3MB /  ??.?MB @   5.1MB/s  6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m  30.8MB /  ??.?MB @   5.1MB/s  6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m  31.0MB /  ??.?MB @   5.0MB/s  6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m  31.5MB /  ??.?MB @   5.0MB/s  6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m  32.0MB /  ??.?MB @   5.0MB/s  6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m  32.5MB /  ??.?MB @   5.0MB/s  6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "conda-forge/linux-64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m  32.5MB /  ??.?MB @   5.0MB/s  6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   5.0MB/s Finalizing  6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   5.0MB/s Finalizing  6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   5.0MB/s Finalizing  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   5.0MB/s Finalizing  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   5.0MB/s Finalizing  7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                               @   5.0MB/s  7.2s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.11.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/progyan/miniconda/envs/mamba-env\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - sentencepiece\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                    Version  Build             Channel                   Size\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ aws-c-auth          \u001b[0m      0.6.24  h84a1944_5        conda-forge/linux-64      95kB\n",
      "  \u001b[32m+ aws-c-cal           \u001b[0m      0.5.20  hc60faf5_6        conda-forge/linux-64      43kB\n",
      "  \u001b[32m+ aws-c-compression   \u001b[0m      0.2.16  h034cb4b_3        conda-forge/linux-64      19kB\n",
      "  \u001b[32m+ aws-c-http          \u001b[0m       0.7.4  hf084cc8_2        conda-forge/linux-64     192kB\n",
      "  \u001b[32m+ aws-c-io            \u001b[0m     0.13.17  h10df833_2        conda-forge/linux-64     143kB\n",
      "  \u001b[32m+ aws-c-mqtt          \u001b[0m       0.8.6  hc41645a_6        conda-forge/linux-64     144kB\n",
      "  \u001b[32m+ aws-c-s3            \u001b[0m       0.2.4  h1b8f470_3        conda-forge/linux-64      75kB\n",
      "  \u001b[32m+ aws-c-sdkutils      \u001b[0m       0.1.7  h034cb4b_3        conda-forge/linux-64      52kB\n",
      "  \u001b[32m+ aws-crt-cpp         \u001b[0m      0.19.7  h0073717_7        conda-forge/linux-64     318kB\n",
      "  \u001b[32m+ libabseil           \u001b[0m  20220623.0  cxx17_h05df665_6  conda-forge/linux-64       1MB\n",
      "  \u001b[32m+ libarrow            \u001b[0m      11.0.0  h2ebd325_5_cpu    conda-forge/linux-64      27MB\n",
      "  \u001b[32m+ libcrc32c           \u001b[0m       1.1.2  h9c3ff4c_0        conda-forge/linux-64      20kB\n",
      "  \u001b[32m+ libgoogle-cloud     \u001b[0m       2.7.0  h21dfe5b_1        conda-forge/linux-64      37MB\n",
      "  \u001b[32m+ libgrpc             \u001b[0m      1.51.1  h4fad500_1        conda-forge/linux-64       5MB\n",
      "  \u001b[32m+ libsentencepiece    \u001b[0m      0.1.97  h43f1d4c_0        conda-forge/linux-64     826kB\n",
      "  \u001b[32m+ libutf8proc         \u001b[0m       2.8.0  h166bdaf_0        conda-forge/linux-64     101kB\n",
      "  \u001b[32m+ s2n                 \u001b[0m      1.3.37  h3358134_0        conda-forge/linux-64     361kB\n",
      "  \u001b[32m+ sentencepiece       \u001b[0m      0.1.97  h38be061_0        conda-forge/linux-64      31kB\n",
      "  \u001b[32m+ sentencepiece-python\u001b[0m      0.1.97  py311h1d730ea_0   conda-forge/linux-64       2MB\n",
      "  \u001b[32m+ sentencepiece-spm   \u001b[0m      0.1.97  h43f1d4c_0        conda-forge/linux-64      84kB\n",
      "\n",
      "  Change:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- arrow-cpp           \u001b[0m      11.0.0  h374c478_1        pkgs/main                     \n",
      "  \u001b[32m+ arrow-cpp           \u001b[0m      11.0.0  ha770c72_5_cpu    conda-forge/linux-64      31kB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- abseil-cpp          \u001b[0m  20211102.0  h27087fc_1        conda-forge                   \n",
      "  \u001b[32m+ abseil-cpp          \u001b[0m  20220623.0  h8cdb687_6        conda-forge/linux-64      17kB\n",
      "  \u001b[31m- aws-c-common        \u001b[0m       0.6.8  h5eee18b_1        pkgs/main                     \n",
      "  \u001b[32m+ aws-c-common        \u001b[0m      0.8.11  h0b41bf4_0        conda-forge/linux-64     199kB\n",
      "  \u001b[31m- aws-c-event-stream  \u001b[0m       0.1.6  h6a678d5_6        pkgs/main                     \n",
      "  \u001b[32m+ aws-c-event-stream  \u001b[0m      0.2.18  h75388cd_6        conda-forge/linux-64      53kB\n",
      "  \u001b[31m- aws-checksums       \u001b[0m      0.1.11  h5eee18b_2        pkgs/main                     \n",
      "  \u001b[32m+ aws-checksums       \u001b[0m      0.1.14  h034cb4b_3        conda-forge/linux-64      50kB\n",
      "  \u001b[31m- aws-sdk-cpp         \u001b[0m     1.8.185  h721c034_1        pkgs/main                     \n",
      "  \u001b[32m+ aws-sdk-cpp         \u001b[0m     1.10.57  h4707e7a_4        conda-forge/linux-64       4MB\n",
      "  \u001b[31m- glog                \u001b[0m       0.5.0  h48cff8f_0        conda-forge                   \n",
      "  \u001b[32m+ glog                \u001b[0m       0.6.0  h6f12383_0        conda-forge/linux-64     114kB\n",
      "  \u001b[31m- grpc-cpp            \u001b[0m      1.48.2  he1ff14a_1        pkgs/main                     \n",
      "  \u001b[32m+ grpc-cpp            \u001b[0m      1.51.1  h27aab58_1        conda-forge/linux-64      21kB\n",
      "  \u001b[31m- libprotobuf         \u001b[0m      3.20.3  h3eb15da_0        conda-forge                   \n",
      "  \u001b[32m+ libprotobuf         \u001b[0m     3.21.12  h3eb15da_0        conda-forge/linux-64       2MB\n",
      "  \u001b[31m- libthrift           \u001b[0m      0.15.0  h362ad58_1        conda-forge                   \n",
      "  \u001b[32m+ libthrift           \u001b[0m      0.18.0  h5e4af38_0        conda-forge/linux-64       4MB\n",
      "  \u001b[31m- orc                 \u001b[0m       1.7.4  hb3bc3d3_1        pkgs/main                     \n",
      "  \u001b[32m+ orc                 \u001b[0m       1.8.2  hfdbbad2_2        conda-forge/linux-64     907kB\n",
      "  \u001b[31m- re2                 \u001b[0m  2022.04.01  h27087fc_0        conda-forge                   \n",
      "  \u001b[32m+ re2                 \u001b[0m  2023.02.01  hcb278e6_0        conda-forge/linux-64     201kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 20 packages\n",
      "  Change: 1 packages\n",
      "  Upgrade: 11 packages\n",
      "\n",
      "  Total download: 86MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading  (1) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B libprotobuf                0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "Downloading  (5) \u001b[33m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B libprotobuf                0.1s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gglog                                               114.3kB @   1.1MB/s  0.1s\n",
      "libcrc32c                                           20.4kB @ 134.5kB/s  0.0s\n",
      "libutf8proc                                        101.1kB @ 656.9kB/s  0.2s\n",
      "[+] 0.2s\n",
      "Downloading  (5) \u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2.8MB libprotobuf                0.2s\n",
      "Extracting   (3) \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m       0 glog                       0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibthrift                                            3.6MB @  15.7MB/s  0.2s\n",
      "aws-c-compression                                   18.8kB @  81.4kB/s  0.0s\n",
      "[+] 0.3s\n",
      "Downloading  (5) \u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3.9MB libprotobuf                0.3s\n",
      "Extracting   (2) ━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m       3 aws-c-compression          0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-c-cal                                           43.3kB @ 142.4kB/s  0.1s\n",
      "sentencepiece-spm                                   84.4kB @ 276.9kB/s  0.1s\n",
      "aws-c-http                                         191.6kB @ 516.2kB/s  0.1s\n",
      "aws-c-event-stream                                  52.8kB @ 141.9kB/s  0.1s\n",
      "[+] 0.4s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   5.1MB libsentencepiece           0.4s\n",
      "Extracting   (2) ━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m       7 aws-c-event-stream         0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibsentencepiece                                   826.5kB @   1.9MB/s  0.3s\n",
      "[+] 0.5s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   5.5MB aws-sdk-cpp                0.5s\n",
      "Extracting   (1) ━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m       9 libsentencepiece           0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-sdk-cpp                                          4.2MB @   8.1MB/s  0.1s\n",
      "orc                                                907.0kB @   1.8MB/s  0.1s\n",
      "aws-c-sdkutils                                      52.4kB @  91.0kB/s  0.1s\n",
      "[+] 0.6s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  10.7MB libabseil                  0.6s\n",
      "Extracting   (2) ━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      11 aws-c-sdkutils             0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  21.1MB libabseil                  0.7s\n",
      "Extracting   (1) ━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      12 aws-sdk-cpp                0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsentencepiece                                       30.8kB @  43.0kB/s  0.1s\n",
      "aws-c-s3                                            75.3kB @  99.9kB/s  0.0s\n",
      "arrow-cpp                                           31.0kB @  39.0kB/s  0.0s\n",
      "[+] 0.8s\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  25.5MB libabseil                  0.8s\n",
      "Extracting   (2) ━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      14 arrow-cpp                  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gabseil-cpp                                          17.1kB @  20.5kB/s  0.0s\n",
      "[+] 0.9s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  32.2MB libabseil                  0.9s\n",
      "Extracting   (1) ━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      16 abseil-cpp                 0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  40.9MB libarrow                   1.0s\n",
      "Extracting       ━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━\u001b[0m      17                            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  50.8MB libarrow                   1.1s\n",
      "Extracting       ━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━\u001b[0m      17                            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgoogle-cloud                                     36.6MB @  31.0MB/s  0.7s\n",
      "[+] 1.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  60.7MB libarrow                   1.2s\n",
      "Extracting   (1) ━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      17 libgoogle-cloud            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibprotobuf                                          2.2MB @   1.8MB/s  1.2s\n",
      "aws-c-auth                                          94.7kB @  78.2kB/s  0.0s\n",
      "aws-c-common                                       198.7kB @ 154.1kB/s  0.1s\n",
      "[+] 1.3s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━\u001b[0m  68.7MB libarrow                   1.3s\n",
      "Extracting   (4) ━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      17 libgoogle-cloud            0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-checksums                                       50.0kB @  36.8kB/s  0.2s\n",
      "aws-c-mqtt                                         143.6kB @ 105.6kB/s  0.1s\n",
      "[+] 1.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━\u001b[0m  72.3MB libgrpc                    1.4s\n",
      "Extracting   (3) ━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      20 libgoogle-cloud            1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gs2n                                                360.6kB @ 250.4kB/s  0.1s\n",
      "libarrow                                            26.9MB @  18.5MB/s  1.1s\n",
      "[+] 1.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━\u001b[0m  80.5MB libgrpc                    1.5s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      22 libgoogle-cloud            1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gre2                                                200.7kB @ 134.0kB/s  0.1s\n",
      "aws-c-io                                           143.1kB @  92.9kB/s  0.0s\n",
      "[+] 1.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  83.1MB libgrpc                    1.6s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━\u001b[0m      24 s2n                        1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgrpc                                              5.3MB @   3.3MB/s  0.2s\n",
      "grpc-cpp                                            21.3kB @  13.2kB/s  0.2s\n",
      "aws-crt-cpp                                        318.4kB @ 196.9kB/s  0.1s\n",
      "[+] 1.7s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  83.7MB libabseil                  1.7s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━\u001b[0m      26 aws-crt-cpp                1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "Downloading  (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  84.1MB libabseil                  1.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━\u001b[0m      27 libarrow                   1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsentencepiece-python                                 2.3MB @   1.2MB/s  1.0s\n",
      "[+] 1.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  1.9s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      28 libarrow                   1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.0s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      28 libarrow                   1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.1s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.2s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.3s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.4s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.5s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.6s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.7s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.8s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  2.9s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  3.0s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  85.1MB libabseil                  3.1s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibabseil                                            1.1MB @ 354.8kB/s  3.1s\n",
      "[+] 3.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  86.2MB                            3.2s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      31 libabseil                  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  86.2MB                            3.2s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━━━      32                            1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!mamba install -c conda-forge sentencepiece -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# replace \"cpu\" with \"cuda\" to use your GPU\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecapoda-research/llama-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mLlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecapoda-research/llama-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe capital of Canada is\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     11\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/transformers/utils/import_utils.py:1026\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1026\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/transformers/utils/import_utils.py:1014\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1012\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "device = \"cpu\"  # replace \"cpu\" with \"cuda\" to use your GPU\n",
    "\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\").to(device)\n",
    "\n",
    "batch = tokenizer(\n",
    "    \"The capital of Canada is\",\n",
    "    return_tensors=\"pt\", \n",
    "    add_special_tokens=False\n",
    ")\n",
    "\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "generated = model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 68.86it/s]\n"
     ]
    }
   ],
   "source": [
    "zeroshot_weights = zeroshot_classifier(classes, context_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/akash/ZERO-SHOT-INF/datasets/BigEarthNet-S2//rasters/S2A_MSIL2A_20170613T101031_12_40.tif'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bens2_ds.vec_df.loc[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [22:15<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0682, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bens2_dl = DataLoader(bens2_ds, batch_size=bsize, shuffle=False, num_workers=num_workers)\n",
    "acc_inst = MultilabelAccuracy(num_labels=num_classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(bens2_dl):\n",
    "        images = sample[\"image\"].to(device)\n",
    "        target = sample[\"label\"].to(device)\n",
    "\n",
    "        im_features = model.encode_image(images)\n",
    "        im_features /= im_features.norm(dim=-1, keepdim=True)\n",
    "        logits = 1.* im_features @ zeroshot_weights\n",
    "        preds = torch.sigmoid(logits)\n",
    "\n",
    "        acc_inf= acc_inst(preds, target)\n",
    "\n",
    "    avg_acc_inf = acc_inst.compute()\n",
    "    print(avg_acc_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreds\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0', dtype=torch.int16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigearth",
   "language": "python",
   "name": "mamba-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3f1a4860803b1f39012e366d11a657a8b07de5def2fd4a51357a35c78539319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
