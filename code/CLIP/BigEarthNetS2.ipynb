{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, clip, csv, json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rasterio.enums import Resampling\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"geolibs/data/BigEarthNet-S2\"\n",
    "bsize, psize = 512, 336\n",
    "num_workers = 8\n",
    "\n",
    "model_name = \"ViT-L/14@336px\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image-id</th>\n",
       "      <th>image:01</th>\n",
       "      <th>date:01</th>\n",
       "      <th>type</th>\n",
       "      <th>geometry</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63a44d38d053bf87a930ddb4</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_0_49.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63a44d38d053bf87a930ddc1</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_0_62.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63a44d38d053bf87a930de15</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_11_41.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63a44d38d053bf87a930de5c</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_12_59.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>63a44d38d053bf87a930de74</td>\n",
       "      <td>rasters/raw/S2A_MSIL2A_20170613T101031_12_83.tar</td>\n",
       "      <td>2017-06-13T10:10:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea and ocean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  image-id  \\\n",
       "0           0  63a44d38d053bf87a930ddb4   \n",
       "1           1  63a44d38d053bf87a930ddc1   \n",
       "2           2  63a44d38d053bf87a930de15   \n",
       "3           3  63a44d38d053bf87a930de5c   \n",
       "4           4  63a44d38d053bf87a930de74   \n",
       "\n",
       "                                           image:01  \\\n",
       "0   rasters/raw/S2A_MSIL2A_20170613T101031_0_49.tar   \n",
       "1   rasters/raw/S2A_MSIL2A_20170613T101031_0_62.tar   \n",
       "2  rasters/raw/S2A_MSIL2A_20170613T101031_11_41.tar   \n",
       "3  rasters/raw/S2A_MSIL2A_20170613T101031_12_59.tar   \n",
       "4  rasters/raw/S2A_MSIL2A_20170613T101031_12_83.tar   \n",
       "\n",
       "                     date:01  type  geometry         labels  \n",
       "0  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "1  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "2  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "3  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  \n",
       "4  2017-06-13T10:10:31+00:00   NaN       NaN  Sea and ocean  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV/val.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    means = [0.48145, 0.45782, 0.40821]\n",
    "    stds = [0.26863, 0.26130, 0.27578]\n",
    "\n",
    "    image = image / 255\n",
    "    for idx in range(3):\n",
    "        image[idx,:,:] = (image[idx,:,:]-means[idx])/stds[idx]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BigEarthNetS2InferenceDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        root_vec_dir = \"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV\"\n",
    "        meta_file = \"/mnt/NVME2/geolibs/data/BigEarthNet-S2/vectors/random-split-6_2022_12_30-01_32_22/CSV/metadata.json\"\n",
    "        rasters_root_dir = \"/home/progyan/data/cogs/\"\n",
    "        with open(meta_file) as out:\n",
    "            task_meta = json.load(out)\n",
    "\n",
    "        classes = [lbl_meta[\"options\"] for lbl_meta in task_meta[\"label:metadata\"]][0]\n",
    "        cls_idx_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        \n",
    "        vec_df = pd.read_csv(f\"{root_vec_dir}/test.csv\")\n",
    "        vec_df[\"image\"] = vec_df[\"image:01\"].apply(lambda x: f'{rasters_root_dir}{x.split(\"/\")[-1]}')\n",
    "        vec_df[\"image\"] = vec_df[\"image\"].apply(lambda x: f'{x.split(\".\")[0]}.tif')\n",
    "        vec_df[\"label\"] = vec_df[\"labels\"].apply(lambda x: [cls_idx_map[l] for l in x.split(\"\\t\")])\n",
    "        vec_df[\"label\"] = vec_df[\"label\"].apply(lambda x: [1 if i in x else 0 for i in range(len(classes))])\n",
    "        vec_df.drop(['image-id','image:01','date:01','type','geometry','labels'],axis=1,inplace=True)\n",
    "\n",
    "        self.vec_df = vec_df\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vec_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df_entry = self.vec_df.loc[idx]\n",
    "        image = rio.open(df_entry[\"image\"]).read(out_shape=[3,psize,psize], resampling=Resampling.bilinear)    \n",
    "        smpl_map = {\n",
    "            \"image\": normalize(image),\n",
    "            \"label\": np.array(df_entry[\"label\"], dtype=np.int16)\n",
    "        }\n",
    "\n",
    "        return smpl_map\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of many {}.',\n",
    "    'a sculpture of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a tattoo of a {}.',\n",
    "    'the embroidered {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'the plastic {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a plastic {}.',\n",
    "    'a photo of the dirty {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a {} in a video game.',\n",
    "    'a photo of one {}.',\n",
    "    'a doodle of a {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'the origami {}.',\n",
    "    'the {} in a video game.',\n",
    "    'a sketch of a {}.',\n",
    "    'a doodle of the {}.',\n",
    "    'a origami {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'the toy {}.',\n",
    "    'a rendition of the {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a rendition of a {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a photo of a weird {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a sketch of the {}.',\n",
    "    'a embroidered {}.',\n",
    "    'a pixelated photo of a {}.',\n",
    "    'itap of the {}.',\n",
    "    'a jpeg corrupted photo of the {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a plushie {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'the cartoon {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a black and white photo of a {}.',\n",
    "    'the plushie {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'itap of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "    'a toy {}.',\n",
    "    'itap of my {}.',\n",
    "    'a photo of a cool {}.',\n",
    "    'a photo of a small {}.',\n",
    "    'a tattoo of the {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_templates = [\n",
    "    \"an overhead view of a {}\",\n",
    "    \"a satellite view of a {}\",\n",
    "    \"an aerial view of a {}\",\n",
    "    \"a clear overhead view of a {}\",\n",
    "    \"a blurry overhead view of a {}\",\n",
    "    \"a low resolution overhead view of a {}\",\n",
    "    \"a high resolution overhead view of a {}\",\n",
    "    \"a clear satellite view of a {}\",\n",
    "    \"a blurry satellite view of a {}\",\n",
    "    \"a low resolution satellite view of a {}\",\n",
    "    \"a high resolution satellite view of a {}\",\n",
    "    \"a clear satellite view of a {}\",\n",
    "    \"a blurry satellite view of a {}\",\n",
    "    \"a low resolution satellite view of a {}\",\n",
    "    \"a high resolution satellite view of a {}\",\n",
    "    \"an overhead image of a {}\",\n",
    "    \"a satellite image of a {}\",\n",
    "    \"an aerial image of a {}\",\n",
    "    \"a clear overhead image of a {}\",\n",
    "    \"a blurry overhead image of a {}\",\n",
    "    \"a low resolution overhead image of a {}\",\n",
    "    \"a high resolution overhead image of a {}\",\n",
    "    \"a clear satellite image of a {}\",\n",
    "    \"a blurry satellite image of a {}\",\n",
    "    \"a low resolution satellite image of a {}\",\n",
    "    \"a high resolution satellite image of a {}\",\n",
    "    \"a clear satellite image of a {}\",\n",
    "    \"a blurry satellite image of a {}\",\n",
    "    \"a low resolution satellite image of a {}\",\n",
    "    \"a high resolution satellite image of a {}\",  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zeroshot_classifier(classnames, templates):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            texts = [template.format(classname) for template in templates] #format with class\n",
    "            texts = clip.tokenize(texts).cuda() #tokenize\n",
    "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geolibs/data/BigEarthNet-S2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bens2_ds = BigEarthNetS2InferenceDataset(root_dir=root_dir)\n",
    "\n",
    "classes = bens2_ds.classes\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"an image of {cls}\" for cls in bens2_ds.classes]\n",
    "texts = clip.tokenize(texts).to(device)\n",
    "\n",
    "text_features = model.encode_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/246 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 23.70 GiB total capacity; 16.84 GiB already allocated; 962.50 MiB free; 20.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m images \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m target \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 25\u001b[0m im_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m model(images, texts)\n\u001b[1;32m     29\u001b[0m preds_01 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(logits_per_image,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:341\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:232\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(x)\n\u001b[1;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NLD -> LND\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# LND -> NLD\u001b[39;00m\n\u001b[1;32m    235\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x[:, \u001b[38;5;241m0\u001b[39m, :])\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:191\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    190\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m--> 191\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/clip/model.py:168\u001b[0m, in \u001b[0;36mQuickGELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.702\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 23.70 GiB total capacity; 16.84 GiB already allocated; 962.50 MiB free; 20.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import HammingDistance, Accuracy\n",
    "\n",
    "acc_inst_01 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_02 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_03 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_04 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_05 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_06 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "acc_inst_07 = Accuracy(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "\n",
    "bens2_dl = DataLoader(bens2_ds, batch_size=bsize, shuffle=False, num_workers=num_workers)\n",
    "# acc_inst = MultilabelAccuracy(num_labels=num_classes).to(device)\n",
    "\n",
    "# ham_dist_03 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_04 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_05 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_06 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "# ham_dist_07 = HammingDistance(task=\"multilabel\", num_labels=num_classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(bens2_dl):\n",
    "        images = sample[\"image\"].to(device)\n",
    "        target = sample[\"label\"].to(device)\n",
    "        \n",
    "        im_features = model.encode_image(images)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        \n",
    "        preds_01 = torch.topk(logits_per_image,1).indices\n",
    "        preds_02 = torch.topk(logits_per_image,2).indices\n",
    "        preds_03 = torch.topk(logits_per_image,3).indices\n",
    "        preds_04 = torch.topk(logits_per_image,4).indices\n",
    "        preds_05 = torch.topk(logits_per_image,5).indices\n",
    "        preds_06 = torch.topk(logits_per_image,6).indices\n",
    "        preds_07 = torch.topk(logits_per_image,7).indices\n",
    "\n",
    "        oh_preds_01 = F.one_hot(preds_01, num_classes).squeeze(1)\n",
    "        oh_preds_02 = torch.sum(F.one_hot(preds_02, num_classes),1)\n",
    "        oh_preds_03 = torch.sum(F.one_hot(preds_03, num_classes),1)\n",
    "        oh_preds_04 = torch.sum(F.one_hot(preds_04, num_classes),1)\n",
    "        oh_preds_05 = torch.sum(F.one_hot(preds_05, num_classes),1)\n",
    "        oh_preds_06 = torch.sum(F.one_hot(preds_06, num_classes),1)\n",
    "        oh_preds_07 = torch.sum(F.one_hot(preds_07, num_classes),1)\n",
    "\n",
    "        acc_inf_01 = acc_inst_01(oh_preds_01, target)\n",
    "        acc_inf_02 = acc_inst_02(oh_preds_02, target)\n",
    "        acc_inf_03 = acc_inst_03(oh_preds_03, target)\n",
    "        acc_inf_04 = acc_inst_04(oh_preds_04, target)\n",
    "        acc_inf_05 = acc_inst_05(oh_preds_05, target)\n",
    "        acc_inf_06 = acc_inst_06(oh_preds_06, target)\n",
    "        acc_inf_07 = acc_inst_07(oh_preds_07, target)\n",
    "\n",
    "        # ham_dist_inf_03 = ham_dist_03(oh_preds_03, target)\n",
    "        # ham_dist_inf_04 = ham_dist_04(oh_preds_04, target)\n",
    "        # ham_dist_inf_05 = ham_dist_05(oh_preds_05, target)\n",
    "        # ham_dist_inf_06 = ham_dist_06(oh_preds_06, target)\n",
    "        # ham_dist_inf_07 = ham_dist_07(oh_preds_07, target)\n",
    "        #acc_inf= acc_inst(oh_preds, target)\n",
    "\n",
    "    avg_acc_inst_01 = acc_inst_01.compute()\n",
    "    avg_acc_inst_02 = acc_inst_02.compute()\n",
    "    avg_acc_inst_03 = acc_inst_03.compute()\n",
    "    avg_acc_inst_04 = acc_inst_04.compute()\n",
    "    avg_acc_inst_05 = acc_inst_05.compute()\n",
    "    avg_acc_inst_06 = acc_inst_06.compute()\n",
    "    avg_acc_inst_07 = acc_inst_07.compute()\n",
    "\n",
    "    # avg_ham_dist_03 = ham_dist_03.compute()\n",
    "    # avg_ham_dist_04 = ham_dist_04.compute()\n",
    "    # avg_ham_dist_05 = ham_dist_05.compute()\n",
    "    # avg_ham_dist_06 = ham_dist_06.compute()\n",
    "    # avg_ham_dist_07 = ham_dist_07.compute()\n",
    "    print(f\"top 1: {avg_acc_inst_01}\")\n",
    "    print(f\"top 2: {avg_acc_inst_02}\")   \n",
    "    print(f\"top 3: {avg_acc_inst_03}\")\n",
    "    print(f\"top 4: {avg_acc_inst_04}\")\n",
    "    print(f\"top 5: {avg_acc_inst_05}\")\n",
    "    print(f\"top 6: {avg_acc_inst_06}\")\n",
    "    print(f\"top 7: {avg_acc_inst_07}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "oh_preds_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vec_df = pd.read_csv(f\"/mnt/NVME2/{root_dir}/vectors/random-split-6_2022_12_30-01_32_22/CSV/test.csv\")\n",
    "vec_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/progyan/miniconda/envs/mamba-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - transformers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    abseil-cpp-20211102.0      |       h27087fc_1         1.1 MB  conda-forge\n",
      "    aiohttp-3.8.4              |  py311h459d7ec_1         538 KB  conda-forge\n",
      "    aiosignal-1.3.1            |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    async-timeout-4.0.2        |     pyhd8ed1ab_0           9 KB  conda-forge\n",
      "    datasets-2.13.0            |     pyhd8ed1ab_0         333 KB  conda-forge\n",
      "    dill-0.3.6                 |     pyhd8ed1ab_1          81 KB  conda-forge\n",
      "    frozenlist-1.3.3           |  py311hd4cff14_0          45 KB  conda-forge\n",
      "    fsspec-2023.6.0            |     pyh1a96a4e_0         116 KB  conda-forge\n",
      "    gflags-2.2.2               |    he1b5a44_1004         114 KB  conda-forge\n",
      "    glog-0.5.0                 |       h48cff8f_0         104 KB  conda-forge\n",
      "    huggingface_hub-0.15.1     |     pyhd8ed1ab_0         165 KB  conda-forge\n",
      "    joblib-1.2.0               |     pyhd8ed1ab_0         205 KB  conda-forge\n",
      "    libevent-2.1.10            |       h28343ad_4         1.1 MB  conda-forge\n",
      "    libprotobuf-3.20.3         |       h3eb15da_0         2.2 MB  conda-forge\n",
      "    libthrift-0.15.0           |       h362ad58_1         4.5 MB  conda-forge\n",
      "    multidict-6.0.4            |  py311h2582759_0          56 KB  conda-forge\n",
      "    multiprocess-0.70.14       |  py311hd4cff14_3         315 KB  conda-forge\n",
      "    python-xxhash-3.2.0        |  py311h2582759_0          22 KB  conda-forge\n",
      "    re2-2022.04.01             |       h27087fc_0         212 KB  conda-forge\n",
      "    regex-2023.6.3             |  py311h459d7ec_0         395 KB  conda-forge\n",
      "    responses-0.18.0           |     pyhd8ed1ab_0          35 KB  conda-forge\n",
      "    sacremoses-0.0.53          |     pyhd8ed1ab_0         427 KB  conda-forge\n",
      "    safetensors-0.3.1          |  py311h46250e7_0         973 KB  conda-forge\n",
      "    tokenizers-0.13.3          |  py311h1b04a43_0         3.9 MB  conda-forge\n",
      "    transformers-4.30.2        |     pyhd8ed1ab_1         2.4 MB  conda-forge\n",
      "    xxhash-0.8.1               |       h0b41bf4_0          87 KB  conda-forge\n",
      "    yarl-1.9.2                 |  py311h459d7ec_0         103 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        19.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  abseil-cpp         conda-forge/linux-64::abseil-cpp-20211102.0-h27087fc_1 \n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.8.4-py311h459d7ec_1 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  arrow-cpp          pkgs/main/linux-64::arrow-cpp-11.0.0-h374c478_1 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0 \n",
      "  aws-c-common       pkgs/main/linux-64::aws-c-common-0.6.8-h5eee18b_1 \n",
      "  aws-c-event-stream pkgs/main/linux-64::aws-c-event-stream-0.1.6-h6a678d5_6 \n",
      "  aws-checksums      pkgs/main/linux-64::aws-checksums-0.1.11-h5eee18b_2 \n",
      "  aws-sdk-cpp        pkgs/main/linux-64::aws-sdk-cpp-1.8.185-h721c034_1 \n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3 \n",
      "  datasets           conda-forge/noarch::datasets-2.13.0-pyhd8ed1ab_0 \n",
      "  dill               conda-forge/noarch::dill-0.3.6-pyhd8ed1ab_1 \n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.3.3-py311hd4cff14_0 \n",
      "  fsspec             conda-forge/noarch::fsspec-2023.6.0-pyh1a96a4e_0 \n",
      "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004 \n",
      "  glog               conda-forge/linux-64::glog-0.5.0-h48cff8f_0 \n",
      "  grpc-cpp           pkgs/main/linux-64::grpc-cpp-1.48.2-he1ff14a_1 \n",
      "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.15.1-pyhd8ed1ab_0 \n",
      "  joblib             conda-forge/noarch::joblib-1.2.0-pyhd8ed1ab_0 \n",
      "  libevent           conda-forge/linux-64::libevent-2.1.10-h28343ad_4 \n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.20.3-h3eb15da_0 \n",
      "  libthrift          conda-forge/linux-64::libthrift-0.15.0-h362ad58_1 \n",
      "  multidict          conda-forge/linux-64::multidict-6.0.4-py311h2582759_0 \n",
      "  multiprocess       conda-forge/linux-64::multiprocess-0.70.14-py311hd4cff14_3 \n",
      "  orc                pkgs/main/linux-64::orc-1.7.4-hb3bc3d3_1 \n",
      "  pyarrow            pkgs/main/linux-64::pyarrow-11.0.0-py311hd8e8d9b_0 \n",
      "  python-xxhash      conda-forge/linux-64::python-xxhash-3.2.0-py311h2582759_0 \n",
      "  re2                conda-forge/linux-64::re2-2022.04.01-h27087fc_0 \n",
      "  regex              conda-forge/linux-64::regex-2023.6.3-py311h459d7ec_0 \n",
      "  responses          conda-forge/noarch::responses-0.18.0-pyhd8ed1ab_0 \n",
      "  sacremoses         conda-forge/noarch::sacremoses-0.0.53-pyhd8ed1ab_0 \n",
      "  safetensors        conda-forge/linux-64::safetensors-0.3.1-py311h46250e7_0 \n",
      "  tokenizers         conda-forge/linux-64::tokenizers-0.13.3-py311h1b04a43_0 \n",
      "  transformers       conda-forge/noarch::transformers-4.30.2-pyhd8ed1ab_1 \n",
      "  utf8proc           pkgs/main/linux-64::utf8proc-2.6.1-h27cfd23_0 \n",
      "  xxhash             conda-forge/linux-64::xxhash-0.8.1-h0b41bf4_0 \n",
      "  yarl               conda-forge/linux-64::yarl-1.9.2-py311h459d7ec_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.05.30~ --> conda-forge::ca-certificates-2023.5.7-hbcca054_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "gflags-2.2.2         | 114 KB    |                                       |   0% \n",
      "responses-0.18.0     | 35 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "gflags-2.2.2         | 114 KB    | #####2                                |  14% \u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     | ######7                               |  18% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | 2                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xxhash-0.8.1         | 87 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ####################3                 |  55% \u001b[A\u001b[A\n",
      "responses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\n",
      "responses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gflags-2.2.2         | 114 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | #######5                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ###############3                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regex-2023.6.3       | 395 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | #######################7              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ###############################1      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ################################7     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiohttp-3.8.4        | 538 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | #######3                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fsspec-2023.6.0      | 116 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##########5                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | ###################################7  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets-2.13.0      | 333 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "glog-0.5.0           | 104 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multiprocess-0.70.14 | 315 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "libprotobuf-3.20.3   | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "safetensors-0.3.1    | 973 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "huggingface_hub-0.15 | 165 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##########################7           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sacremoses-0.0.53    | 427 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aiosignal-1.3.1      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dill-0.3.6           | 81 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizers-0.13.3    | 3.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.2.0         | 205 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abseil-cpp-20211102. | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "multidict-6.0.4      | 56 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers-4.30.2  | 2.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.2.0  | 22 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libevent-2.1.10      | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libthrift-0.15.0     | 4.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge transformers -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth : ['Coniferous forest', 'Mixed forest', 'Transitional woodland/shrub']\n",
      "\n",
      "Top 5: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric']\n",
      "\n",
      "Top 10: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Mixed forest', 'Continuous urban fabric', 'Sparsely vegetated areas', 'Inland marshes']\n",
      "\n",
      "Top 15: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Continuous urban fabric', 'Mixed forest', 'Sparsely vegetated areas', 'Inland marshes', 'Burnt areas', 'Transitional woodland/shrub', 'Non-irrigated arable land', 'Rice fields', 'Mineral extraction sites']\n",
      "\n",
      "Top 20: ['Olive groves', 'Beaches, dunes, sands', 'Water bodies', 'Coniferous forest', 'Discontinuous urban fabric', 'Intertidal flats', 'Mixed forest', 'Continuous urban fabric', 'Sparsely vegetated areas', 'Inland marshes', 'Burnt areas', 'Transitional woodland/shrub', 'Rice fields', 'Non-irrigated arable land', 'Mineral extraction sites', 'Complex cultivation patterns', 'Salt marshes', 'Bare rock', 'Estuaries', 'Sea and ocean']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = preprocess(Image.open(bens2_ds.vec_df.loc[0][\"image\"])).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(bens2_ds.classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "\n",
    "    idx_tp05 = torch.topk(logits_per_image, 5).indices.cpu().tolist()[0]\n",
    "    idx_tp10 = torch.topk(logits_per_image, 10).indices.cpu().tolist()[0]\n",
    "    idx_tp15 = torch.topk(logits_per_image, 15).indices.cpu().tolist()[0]\n",
    "    idx_tp20 = torch.topk(logits_per_image, 20).indices.cpu().tolist()[0]\n",
    "\n",
    "    cls_tp05 = [bens2_ds.classes[idx] for idx in idx_tp05]\n",
    "    cls_tp10 = [bens2_ds.classes[idx] for idx in idx_tp10]\n",
    "    cls_tp15 = [bens2_ds.classes[idx] for idx in idx_tp15]\n",
    "    cls_tp20 = [bens2_ds.classes[idx] for idx in idx_tp20]\n",
    "\n",
    "    gr_truth = vec_df.loc[8]['labels'].split('\\t')\n",
    "    \n",
    "    print(f\"Ground truth : {gr_truth}\")\n",
    "    print(f\"\\nTop 5: {cls_tp05}\")\n",
    "    print(f\"\\nTop 10: {cls_tp10}\")\n",
    "    print(f\"\\nTop 15: {cls_tp15}\")\n",
    "    print(f\"\\nTop 20: {cls_tp20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/progyan/.local/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/progyan/.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/progyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/progyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "/  //  //  //  /\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "                  \n",
      "          \n",
      "        \n",
      "        \n",
      "                \n",
      "                       \n",
      "\n",
      "        mamba (1.4.2) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking for: ['sentencepiece']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/noarch     \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/linux-64      \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/main/noarch     \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "pkgs/r/linux-64      \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64                                               No change\n",
      "pkgs/r/noarch                                                 No change\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m 338.3kB /  ??.?MB @   1.3MB/s  0.3s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\n",
      "pkgs/main/noarch     \u001b[90m\u001b[0m\u001b[33m\u001b[0m 405.5kB /  ??.?MB @   1.6MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch                                   850.6kB @   2.4MB/s  0.4s\n",
      "[+] 0.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.1MB /  ??.?MB @   2.7MB/s  0.4s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   1.6MB /  ??.?MB @   3.2MB/s  0.5s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.5s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   2.2MB /  ??.?MB @   3.6MB/s  0.6s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.6s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   2.6MB /  ??.?MB @   3.7MB/s  0.7s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.7s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.0MB /  ??.?MB @   3.8MB/s  0.8s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.8s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   3.3MB /  ??.?MB @   3.9MB/s  0.9s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.9s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   3.9MB /  ??.?MB @   4.1MB/s  1.0s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.0s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.4MB /  ??.?MB @   4.2MB/s  1.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.1s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.0MB /  ??.?MB @   4.3MB/s  1.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m 429.9kB /  ??.?MB @ 366.2kB/s  1.2s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m 442.4kB /  ??.?MB @ 374.7kB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.5MB /  ??.?MB @   4.4MB/s  1.3s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m 966.2kB /  ??.?MB @ 757.2kB/s  1.3s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m 962.6kB /  ??.?MB @ 751.2kB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.1MB /  ??.?MB @   4.5MB/s  1.4s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   1.6MB /  ??.?MB @   1.1MB/s  1.4s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   1.5MB /  ??.?MB @   1.1MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   6.7MB /  ??.?MB @   4.5MB/s  1.5s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.2MB /  ??.?MB @   1.5MB/s  1.5s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.0MB /  ??.?MB @   1.4MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   7.2MB /  ??.?MB @   4.6MB/s  1.6s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.6MB /  ??.?MB @   1.7MB/s  1.6s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   2.6MB /  ??.?MB @   1.6MB/s  1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   7.8MB /  ??.?MB @   4.6MB/s  1.7s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   3.2MB /  ??.?MB @   1.9MB/s  1.7s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.1MB /  ??.?MB @   1.8MB/s  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m   8.4MB /  ??.?MB @   4.7MB/s  1.8s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   3.7MB /  ??.?MB @   2.1MB/s  1.8s\n",
      "pkgs/main/linux-64   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   3.6MB /  ??.?MB @   2.0MB/s  1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   9.0MB /  ??.?MB @   4.8MB/s  1.9s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.0MB /  ??.?MB @   2.2MB/s  1.9s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.1MB /  ??.?MB @   2.2MB/s  1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m   9.5MB /  ??.?MB @   4.8MB/s  2.0s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.5MB /  ??.?MB @   2.3MB/s  2.0s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   4.7MB /  ??.?MB @   2.3MB/s  2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.1MB /  ??.?MB @   4.8MB/s  2.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.1MB /  ??.?MB @   2.5MB/s  2.1s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.2MB /  ??.?MB @   2.5MB/s  2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.7MB /  ??.?MB @   4.9MB/s  2.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   5.6MB /  ??.?MB @   2.6MB/s  2.2s\n",
      "pkgs/main/linux-64   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.5MB /  ??.?MB @   2.6MB/s  2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.7MB @   4.9MB/s             2.3s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   5.9MB @   2.7MB/s             2.3s\n",
      "pkgs/main/linux-64      5.9MB @   2.6MB/s Finalizing  2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                 @   2.6MB/s  2.3s\n",
      "[+] 2.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  11.2MB /  ??.?MB @   4.8MB/s  2.4s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   6.4MB /  ??.?MB @   2.7MB/s  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  12.1MB /  ??.?MB @   4.9MB/s  2.5s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   7.3MB /  ??.?MB @   2.9MB/s  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  12.6MB /  ??.?MB @   4.9MB/s  2.6s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m   7.8MB /  ??.?MB @   3.0MB/s  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  13.2MB /  ??.?MB @   5.0MB/s  2.7s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   8.4MB /  ??.?MB @   3.1MB/s  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  13.8MB /  ??.?MB @   5.0MB/s  2.8s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   8.9MB /  ??.?MB @   3.2MB/s  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  14.3MB /  ??.?MB @   5.0MB/s  2.9s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m   9.5MB /  ??.?MB @   3.3MB/s  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  14.9MB /  ??.?MB @   5.0MB/s  3.0s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.0MB /  ??.?MB @   3.4MB/s  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  15.4MB /  ??.?MB @   5.0MB/s  3.1s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.5MB /  ??.?MB @   3.4MB/s  3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  16.0MB /  ??.?MB @   5.1MB/s  3.2s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.9MB /  ??.?MB @   3.4MB/s  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  16.5MB /  ??.?MB @   5.1MB/s  3.3s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m  11.5MB /  ??.?MB @   3.5MB/s  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  17.1MB /  ??.?MB @   5.1MB/s  3.4s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m  11.9MB /  ??.?MB @   3.5MB/s  3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  17.7MB /  ??.?MB @   5.1MB/s  3.5s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m  12.3MB /  ??.?MB @   3.5MB/s  3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.2MB /  ??.?MB @   5.1MB/s  3.6s\n",
      "conda-forge/noarch   \u001b[90m\u001b[0m\u001b[33m\u001b[0m  12.7MB /  ??.?MB @   3.5MB/s  3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.4MB /  ??.?MB @   5.1MB/s  3.7s\n",
      "conda-forge/noarch   \u001b[33m\u001b[0m\u001b[90m\u001b[0m  12.9MB /  ??.?MB @   3.6MB/s  3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  18.4MB @   5.1MB/s             3.8s\n",
      "conda-forge/noarch     13.1MB @   3.6MB/s Finalizing  3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                 @   3.6MB/s  3.9s\n",
      "[+] 3.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  19.1MB /  ??.?MB @   4.9MB/s  3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  20.4MB /  ??.?MB @   5.1MB/s  4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  20.7MB /  ??.?MB @   5.1MB/s  4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  21.2MB /  ??.?MB @   5.1MB/s  4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  21.7MB /  ??.?MB @   5.1MB/s  4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  22.2MB /  ??.?MB @   5.1MB/s  4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  22.7MB /  ??.?MB @   5.1MB/s  4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.2MB /  ??.?MB @   5.1MB/s  4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  23.7MB /  ??.?MB @   5.1MB/s  4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  24.2MB /  ??.?MB @   5.1MB/s  4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  24.7MB /  ??.?MB @   5.1MB/s  4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  25.3MB /  ??.?MB @   5.1MB/s  5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  25.9MB /  ??.?MB @   5.1MB/s  5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  26.4MB /  ??.?MB @   5.1MB/s  5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  26.9MB /  ??.?MB @   5.1MB/s  5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  27.4MB /  ??.?MB @   5.1MB/s  5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  27.9MB /  ??.?MB @   5.1MB/s  5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  27.9MB /  ??.?MB @   5.1MB/s  5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  28.9MB /  ??.?MB @   5.1MB/s  5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  29.4MB /  ??.?MB @   5.1MB/s  5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  29.8MB /  ??.?MB @   5.1MB/s  5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m\u001b[90m\u001b[0m  30.3MB /  ??.?MB @   5.1MB/s  6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  30.8MB /  ??.?MB @   5.1MB/s  6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  31.0MB /  ??.?MB @   5.0MB/s  6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  31.5MB /  ??.?MB @   5.0MB/s  6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "conda-forge/linux-64 \u001b[90m\u001b[0m\u001b[33m\u001b[0m  32.0MB /  ??.?MB @   5.0MB/s  6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  32.5MB /  ??.?MB @   5.0MB/s  6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "conda-forge/linux-64 \u001b[33m\u001b[0m\u001b[90m\u001b[0m  32.5MB /  ??.?MB @   5.0MB/s  6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "conda-forge/linux-64   32.6MB @   5.0MB/s Finalizing  6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "conda-forge/linux-64   32.6MB @   5.0MB/s Finalizing  6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "conda-forge/linux-64   32.6MB @   5.0MB/s Finalizing  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "conda-forge/linux-64   32.6MB @   5.0MB/s Finalizing  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "conda-forge/linux-64   32.6MB @   5.0MB/s Finalizing  7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                               @   5.0MB/s  7.2s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.11.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/progyan/miniconda/envs/mamba-env\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - sentencepiece\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                    Version  Build             Channel                   Size\n",
      "\n",
      "  Install:\n",
      "\n",
      "\n",
      "  \u001b[32m+ aws-c-auth          \u001b[0m      0.6.24  h84a1944_5        conda-forge/linux-64      95kB\n",
      "  \u001b[32m+ aws-c-cal           \u001b[0m      0.5.20  hc60faf5_6        conda-forge/linux-64      43kB\n",
      "  \u001b[32m+ aws-c-compression   \u001b[0m      0.2.16  h034cb4b_3        conda-forge/linux-64      19kB\n",
      "  \u001b[32m+ aws-c-http          \u001b[0m       0.7.4  hf084cc8_2        conda-forge/linux-64     192kB\n",
      "  \u001b[32m+ aws-c-io            \u001b[0m     0.13.17  h10df833_2        conda-forge/linux-64     143kB\n",
      "  \u001b[32m+ aws-c-mqtt          \u001b[0m       0.8.6  hc41645a_6        conda-forge/linux-64     144kB\n",
      "  \u001b[32m+ aws-c-s3            \u001b[0m       0.2.4  h1b8f470_3        conda-forge/linux-64      75kB\n",
      "  \u001b[32m+ aws-c-sdkutils      \u001b[0m       0.1.7  h034cb4b_3        conda-forge/linux-64      52kB\n",
      "  \u001b[32m+ aws-crt-cpp         \u001b[0m      0.19.7  h0073717_7        conda-forge/linux-64     318kB\n",
      "  \u001b[32m+ libabseil           \u001b[0m  20220623.0  cxx17_h05df665_6  conda-forge/linux-64       1MB\n",
      "  \u001b[32m+ libarrow            \u001b[0m      11.0.0  h2ebd325_5_cpu    conda-forge/linux-64      27MB\n",
      "  \u001b[32m+ libcrc32c           \u001b[0m       1.1.2  h9c3ff4c_0        conda-forge/linux-64      20kB\n",
      "  \u001b[32m+ libgoogle-cloud     \u001b[0m       2.7.0  h21dfe5b_1        conda-forge/linux-64      37MB\n",
      "  \u001b[32m+ libgrpc             \u001b[0m      1.51.1  h4fad500_1        conda-forge/linux-64       5MB\n",
      "  \u001b[32m+ libsentencepiece    \u001b[0m      0.1.97  h43f1d4c_0        conda-forge/linux-64     826kB\n",
      "  \u001b[32m+ libutf8proc         \u001b[0m       2.8.0  h166bdaf_0        conda-forge/linux-64     101kB\n",
      "  \u001b[32m+ s2n                 \u001b[0m      1.3.37  h3358134_0        conda-forge/linux-64     361kB\n",
      "  \u001b[32m+ sentencepiece       \u001b[0m      0.1.97  h38be061_0        conda-forge/linux-64      31kB\n",
      "  \u001b[32m+ sentencepiece-python\u001b[0m      0.1.97  py311h1d730ea_0   conda-forge/linux-64       2MB\n",
      "  \u001b[32m+ sentencepiece-spm   \u001b[0m      0.1.97  h43f1d4c_0        conda-forge/linux-64      84kB\n",
      "\n",
      "  Change:\n",
      "\n",
      "\n",
      "  \u001b[31m- arrow-cpp           \u001b[0m      11.0.0  h374c478_1        pkgs/main                     \n",
      "  \u001b[32m+ arrow-cpp           \u001b[0m      11.0.0  ha770c72_5_cpu    conda-forge/linux-64      31kB\n",
      "\n",
      "  Upgrade:\n",
      "\n",
      "\n",
      "  \u001b[31m- abseil-cpp          \u001b[0m  20211102.0  h27087fc_1        conda-forge                   \n",
      "  \u001b[32m+ abseil-cpp          \u001b[0m  20220623.0  h8cdb687_6        conda-forge/linux-64      17kB\n",
      "  \u001b[31m- aws-c-common        \u001b[0m       0.6.8  h5eee18b_1        pkgs/main                     \n",
      "  \u001b[32m+ aws-c-common        \u001b[0m      0.8.11  h0b41bf4_0        conda-forge/linux-64     199kB\n",
      "  \u001b[31m- aws-c-event-stream  \u001b[0m       0.1.6  h6a678d5_6        pkgs/main                     \n",
      "  \u001b[32m+ aws-c-event-stream  \u001b[0m      0.2.18  h75388cd_6        conda-forge/linux-64      53kB\n",
      "  \u001b[31m- aws-checksums       \u001b[0m      0.1.11  h5eee18b_2        pkgs/main                     \n",
      "  \u001b[32m+ aws-checksums       \u001b[0m      0.1.14  h034cb4b_3        conda-forge/linux-64      50kB\n",
      "  \u001b[31m- aws-sdk-cpp         \u001b[0m     1.8.185  h721c034_1        pkgs/main                     \n",
      "  \u001b[32m+ aws-sdk-cpp         \u001b[0m     1.10.57  h4707e7a_4        conda-forge/linux-64       4MB\n",
      "  \u001b[31m- glog                \u001b[0m       0.5.0  h48cff8f_0        conda-forge                   \n",
      "  \u001b[32m+ glog                \u001b[0m       0.6.0  h6f12383_0        conda-forge/linux-64     114kB\n",
      "  \u001b[31m- grpc-cpp            \u001b[0m      1.48.2  he1ff14a_1        pkgs/main                     \n",
      "  \u001b[32m+ grpc-cpp            \u001b[0m      1.51.1  h27aab58_1        conda-forge/linux-64      21kB\n",
      "  \u001b[31m- libprotobuf         \u001b[0m      3.20.3  h3eb15da_0        conda-forge                   \n",
      "  \u001b[32m+ libprotobuf         \u001b[0m     3.21.12  h3eb15da_0        conda-forge/linux-64       2MB\n",
      "  \u001b[31m- libthrift           \u001b[0m      0.15.0  h362ad58_1        conda-forge                   \n",
      "  \u001b[32m+ libthrift           \u001b[0m      0.18.0  h5e4af38_0        conda-forge/linux-64       4MB\n",
      "  \u001b[31m- orc                 \u001b[0m       1.7.4  hb3bc3d3_1        pkgs/main                     \n",
      "  \u001b[32m+ orc                 \u001b[0m       1.8.2  hfdbbad2_2        conda-forge/linux-64     907kB\n",
      "  \u001b[31m- re2                 \u001b[0m  2022.04.01  h27087fc_0        conda-forge                   \n",
      "  \u001b[32m+ re2                 \u001b[0m  2023.02.01  hcb278e6_0        conda-forge/linux-64     201kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 20 packages\n",
      "  Change: 1 packages\n",
      "  Upgrade: 11 packages\n",
      "\n",
      "  Total download: 86MB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading  (1) \u001b[90m\u001b[0m   0.0 B libprotobuf                0.0s\n",
      "Extracting       \u001b[90m\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m   0.0 B libprotobuf                0.1s\n",
      "Extracting       \u001b[90m\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gglog                                               114.3kB @   1.1MB/s  0.1s\n",
      "libcrc32c                                           20.4kB @ 134.5kB/s  0.0s\n",
      "libutf8proc                                        101.1kB @ 656.9kB/s  0.2s\n",
      "[+] 0.2s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m   2.8MB libprotobuf                0.2s\n",
      "Extracting   (3) \u001b[33m\u001b[0m\u001b[90m\u001b[0m       0 glog                       0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibthrift                                            3.6MB @  15.7MB/s  0.2s\n",
      "aws-c-compression                                   18.8kB @  81.4kB/s  0.0s\n",
      "[+] 0.3s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m   3.9MB libprotobuf                0.3s\n",
      "Extracting   (2) \u001b[33m\u001b[0m\u001b[90m\u001b[0m       3 aws-c-compression          0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-c-cal                                           43.3kB @ 142.4kB/s  0.1s\n",
      "sentencepiece-spm                                   84.4kB @ 276.9kB/s  0.1s\n",
      "aws-c-http                                         191.6kB @ 516.2kB/s  0.1s\n",
      "aws-c-event-stream                                  52.8kB @ 141.9kB/s  0.1s\n",
      "[+] 0.4s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.1MB libsentencepiece           0.4s\n",
      "Extracting   (2) \u001b[33m\u001b[0m\u001b[90m\u001b[0m       7 aws-c-event-stream         0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibsentencepiece                                   826.5kB @   1.9MB/s  0.3s\n",
      "[+] 0.5s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m   5.5MB aws-sdk-cpp                0.5s\n",
      "Extracting   (1) \u001b[33m\u001b[0m\u001b[90m\u001b[0m       9 libsentencepiece           0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-sdk-cpp                                          4.2MB @   8.1MB/s  0.1s\n",
      "orc                                                907.0kB @   1.8MB/s  0.1s\n",
      "aws-c-sdkutils                                      52.4kB @  91.0kB/s  0.1s\n",
      "[+] 0.6s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  10.7MB libabseil                  0.6s\n",
      "Extracting   (2) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      11 aws-c-sdkutils             0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  21.1MB libabseil                  0.7s\n",
      "Extracting   (1) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      12 aws-sdk-cpp                0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsentencepiece                                       30.8kB @  43.0kB/s  0.1s\n",
      "aws-c-s3                                            75.3kB @  99.9kB/s  0.0s\n",
      "arrow-cpp                                           31.0kB @  39.0kB/s  0.0s\n",
      "[+] 0.8s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  25.5MB libabseil                  0.8s\n",
      "Extracting   (2) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      14 arrow-cpp                  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gabseil-cpp                                          17.1kB @  20.5kB/s  0.0s\n",
      "[+] 0.9s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  32.2MB libabseil                  0.9s\n",
      "Extracting   (1) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      16 abseil-cpp                 0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  40.9MB libarrow                   1.0s\n",
      "Extracting       \u001b[90m\u001b[0m      17                            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  50.8MB libarrow                   1.1s\n",
      "Extracting       \u001b[90m\u001b[0m      17                            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgoogle-cloud                                     36.6MB @  31.0MB/s  0.7s\n",
      "[+] 1.2s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  60.7MB libarrow                   1.2s\n",
      "Extracting   (1) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      17 libgoogle-cloud            0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibprotobuf                                          2.2MB @   1.8MB/s  1.2s\n",
      "aws-c-auth                                          94.7kB @  78.2kB/s  0.0s\n",
      "aws-c-common                                       198.7kB @ 154.1kB/s  0.1s\n",
      "[+] 1.3s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  68.7MB libarrow                   1.3s\n",
      "Extracting   (4) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      17 libgoogle-cloud            0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-checksums                                       50.0kB @  36.8kB/s  0.2s\n",
      "aws-c-mqtt                                         143.6kB @ 105.6kB/s  0.1s\n",
      "[+] 1.4s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  72.3MB libgrpc                    1.4s\n",
      "Extracting   (3) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      20 libgoogle-cloud            1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gs2n                                                360.6kB @ 250.4kB/s  0.1s\n",
      "libarrow                                            26.9MB @  18.5MB/s  1.1s\n",
      "[+] 1.5s\n",
      "Downloading  (5) \u001b[33m\u001b[0m\u001b[90m\u001b[0m  80.5MB libgrpc                    1.5s\n",
      "Extracting   (3) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      22 libgoogle-cloud            1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gre2                                                200.7kB @ 134.0kB/s  0.1s\n",
      "aws-c-io                                           143.1kB @  92.9kB/s  0.0s\n",
      "[+] 1.6s\n",
      "Downloading  (5) \u001b[33m\u001b[0m  83.1MB libgrpc                    1.6s\n",
      "Extracting   (4) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      24 s2n                        1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgrpc                                              5.3MB @   3.3MB/s  0.2s\n",
      "grpc-cpp                                            21.3kB @  13.2kB/s  0.2s\n",
      "aws-crt-cpp                                        318.4kB @ 196.9kB/s  0.1s\n",
      "[+] 1.7s\n",
      "Downloading  (2) \u001b[33m\u001b[0m  83.7MB libabseil                  1.7s\n",
      "Extracting   (4) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      26 aws-crt-cpp                1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "Downloading  (2) \u001b[33m\u001b[0m  84.1MB libabseil                  1.8s\n",
      "Extracting   (3) \u001b[33m\u001b[0m\u001b[90m\u001b[0m      27 libarrow                   1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsentencepiece-python                                 2.3MB @   1.2MB/s  1.0s\n",
      "[+] 1.9s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  1.9s\n",
      "Extracting   (3) \u001b[33m\u001b[0m      28 libarrow                   1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.0s\n",
      "Extracting   (3) \u001b[33m\u001b[0m      28 libarrow                   1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.1s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.2s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.3s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.4s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.5s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.6s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.7s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.8s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  2.9s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  3.0s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "Downloading  (1) \u001b[33m\u001b[0m  85.1MB libabseil                  3.1s\n",
      "Extracting       \u001b[90m\u001b[0m      31                            1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibabseil                                            1.1MB @ 354.8kB/s  3.1s\n",
      "[+] 3.2s\n",
      "Downloading        86.2MB                            3.2s\n",
      "Extracting   (1) \u001b[33m\u001b[0m      31 libabseil                  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "Downloading        86.2MB                            3.2s\n",
      "Extracting             32                            1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!mamba install -c conda-forge sentencepiece -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# replace \"cpu\" with \"cuda\" to use your GPU\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecapoda-research/llama-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mLlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecapoda-research/llama-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe capital of Canada is\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     11\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/transformers/utils/import_utils.py:1026\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1026\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/mamba-env/lib/python3.11/site-packages/transformers/utils/import_utils.py:1014\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1012\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "device = \"cpu\"  # replace \"cpu\" with \"cuda\" to use your GPU\n",
    "\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\").to(device)\n",
    "\n",
    "batch = tokenizer(\n",
    "    \"The capital of Canada is\",\n",
    "    return_tensors=\"pt\", \n",
    "    add_special_tokens=False\n",
    ")\n",
    "\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "generated = model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 43/43 [00:00<00:00, 68.86it/s]\n"
     ]
    }
   ],
   "source": [
    "zeroshot_weights = zeroshot_classifier(classes, context_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/akash/ZERO-SHOT-INF/datasets/BigEarthNet-S2//rasters/S2A_MSIL2A_20170613T101031_12_40.tif'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bens2_ds.vec_df.loc[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 246/246 [22:15<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0682, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bens2_dl = DataLoader(bens2_ds, batch_size=bsize, shuffle=False, num_workers=num_workers)\n",
    "acc_inst = MultilabelAccuracy(num_labels=num_classes).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(bens2_dl):\n",
    "        images = sample[\"image\"].to(device)\n",
    "        target = sample[\"label\"].to(device)\n",
    "\n",
    "        im_features = model.encode_image(images)\n",
    "        im_features /= im_features.norm(dim=-1, keepdim=True)\n",
    "        logits = 1.* im_features @ zeroshot_weights\n",
    "        preds = torch.sigmoid(logits)\n",
    "\n",
    "        acc_inf= acc_inst(preds, target)\n",
    "\n",
    "    avg_acc_inf = acc_inst.compute()\n",
    "    print(avg_acc_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreds\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0', dtype=torch.int16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigearth",
   "language": "python",
   "name": "mamba-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3f1a4860803b1f39012e366d11a657a8b07de5def2fd4a51357a35c78539319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
